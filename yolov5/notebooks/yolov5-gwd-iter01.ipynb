{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import shutil as sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Get from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving git cloned yolov5 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'yolov5/*': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!mv yolov5/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI (from -r requirements.txt (line 13))\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-qa1j3rpf\n",
      "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-qa1j3rpf\n",
      "Requirement already satisfied (use --upgrade to upgrade): pycocotools==2.0 from git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 13))\n",
      "Requirement already satisfied: Cython in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.29.20)\n",
      "Collecting numpy==1.17\n",
      "  Using cached numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl (20.3 MB)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.2.0.34)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (3.2.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (5.4.1)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (5.3.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (0.6.0a0+35d732a)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (4.45.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0->-r requirements.txt (line 13)) (46.1.3.post20200325)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->-r requirements.txt (line 5)) (0.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.14.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.6.0.post3)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.14.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.4.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (3.12.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (3.2.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (2.23.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2020.4.5.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 8)) (3.0.1)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=274026 sha256=6d8e7604529a3290904c02a28637c7f9cca382863455d13bd20021f50352a59c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9fqph849/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
      "Successfully built pycocotools\n",
      "\u001b[31mERROR: osmnx 0.14.1 has requirement geopandas>=0.7, but you'll have geopandas 0.6.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: osmnx 0.14.1 has requirement numpy>=1.18, but you'll have numpy 1.17.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kmeans-smote 0.1.2 has requirement imbalanced-learn<0.5,>=0.4.0, but you'll have imbalanced-learn 0.7.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kmeans-smote 0.1.2 has requirement numpy<1.16,>=1.13, but you'll have numpy 1.17.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kmeans-smote 0.1.2 has requirement scikit-learn<0.21,>=0.19.0, but you'll have scikit-learn 0.23.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: hypertools 0.6.2 has requirement scikit-learn<0.22,>=0.19.1, but you'll have scikit-learn 0.23.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: dask-ml 1.5.0 has requirement numpy>=1.17.3, but you'll have numpy 1.17.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.1\n",
      "    Uninstalling numpy-1.18.1:\n",
      "      Successfully uninstalled numpy-1.18.1\n",
      "Successfully installed numpy-1.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/global-wheat-detection/train.csv')\n",
    "bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "for i, column in enumerate(['x', 'y', 'w', 'h']):\n",
    "    df[column] = bboxs[:,i]\n",
    "df.drop(columns=['bbox'], inplace=True)\n",
    "df['x_center'] = df['x'] + df['w']/2\n",
    "df['y_center'] = df['y'] + df['h']/2\n",
    "df['classes'] = 0\n",
    "\n",
    "df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(set(df.image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dbdb51239f41af91976488520f37f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3373.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source ='train'\n",
    "if True:\n",
    "    for fold in [0]:\n",
    "        val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n",
    "        for name,mini in tqdm(df.groupby('image_id')):\n",
    "            if name in val_index:\n",
    "                path2save = 'val2017/'\n",
    "            else:\n",
    "                path2save = 'train2017/'\n",
    "            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n",
    "                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n",
    "            with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n",
    "                row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n",
    "                row = row/1024\n",
    "                row = row.astype(str)\n",
    "                for j in range(len(row)):\n",
    "                    text = ' '.join(row[j])\n",
    "                    f.write(text)\n",
    "                    f.write(\"\\n\")\n",
    "            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n",
    "                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n",
    "            sh.copy(\"../input/global-wheat-detection/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "{'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\n",
      "Namespace(adam=False, batch_size=2, bucket='', cache_images=False, cfg='../input/configyolo5/yolov5x.yaml', data='../input/configyolo5/wheat0.yaml', device='', epochs=1, evolve=False, img_size=[1024], multi_scale=False, name='yolov5x_fold0', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='')\n",
      "Using CPU\n",
      "\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    513920  models.common.Bottleneck                [160, 160]                    \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  1   3311680  models.common.BottleneckCSP             [320, 320, 12]                \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1  1  13228160  models.common.BottleneckCSP             [640, 640, 12]                \n",
      "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
      "  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n",
      "  9                -1  1  36481280  models.common.BottleneckCSP             [1280, 1280, 8]               \n",
      " 10                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n",
      " 11                -1  1     23058  torch.nn.modules.conv.Conv2d            [1280, 18, 1, 1]              \n",
      " 12                -2  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 13           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 14                -1  1   1230080  models.common.Conv                      [1920, 640, 1, 1]             \n",
      " 15                -1  1   5025920  models.common.BottleneckCSP             [640, 640, 4, False]          \n",
      " 16                -1  1     11538  torch.nn.modules.conv.Conv2d            [640, 18, 1, 1]               \n",
      " 17                -2  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1    307840  models.common.Conv                      [960, 320, 1, 1]              \n",
      " 20                -1  1   1258560  models.common.BottleneckCSP             [320, 320, 4, False]          \n",
      " 21                -1  1      5778  torch.nn.modules.conv.Conv2d            [320, 18, 1, 1]               \n",
      " 22      [-1, 16, 11]  1         0  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]]\n",
      "Model Summary: 381 layers, 9.53903e+07 parameters, 9.53903e+07 gradients\n",
      "\n",
      "Optimizer groups: 126 .bias, 132 conv.weight, 123 other\n",
      "Reading image shapes: 100%|███████████████| 2699/2699 [00:00<00:00, 8214.24it/s]\n",
      "Caching labels convertor/fold0/labels/train2017 (2699 found, 0 missing, 0 empty,\n",
      "Saving labels to convertor/fold0/labels/train2017.npy for faster future loading\n",
      "Reading image shapes: 100%|█████████████████| 674/674 [00:00<00:00, 9063.53it/s]\n",
      "Caching labels convertor/fold0/labels/val2017 (674 found, 0 missing, 0 empty, 0 \n",
      "\n",
      "Analyzing anchors... Best Possible Recall (BPR) = 0.9991\n",
      "Image sizes 1024 train, 1024 test\n",
      "Using 2 dataloader workers\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "  0%|                                                  | 0/1350 [00:00<?, ?it/s]^C\n",
      "  0%|                                                  | 0/1350 [00:45<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 394, in <module>\n",
      "    train(hyp)\n",
      "  File \"train.py\", line 265, in train\n",
      "    optimizer.step()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 67, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/sgd.py\", line 112, in step\n",
      "    p.add_(d_p, alpha=-group['lr'])\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 1024 --batch 2 --epochs 1 --data ../input/configyolo5/wheat0.yaml --cfg ../input/configyolo5/yolov5x.yaml --name yolov5x_fold0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
