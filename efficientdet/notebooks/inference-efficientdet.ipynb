{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this kernel used github repos [efficientdet-pytorch](https://github.com/rwightman/efficientdet-pytorch) and [pytorch-image-models](https://github.com/rwightman/pytorch-image-models) by [@rwightman](https://www.kaggle.com/rwightman). Don't forget add stars ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "!pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null\n",
    "!pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../input/timm-efficientdet-pytorch\")\n",
    "sys.path.insert(0, \"../input/omegaconf\")\n",
    "sys.path.insert(0, \"../input/weightedboxesfusion\")\n",
    "\n",
    "from ensemble_boxes import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchEval\n",
    "from effdet.efficientdet import HeadNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_PATH = '../input/global-wheat-detection/test'\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, image_ids, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "        return image, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetRetriever(\n",
    "    image_ids=np.array([path.split('/')[-1][:-4] for path in glob(f'{DATA_ROOT_PATH}/*.jpg')]),\n",
    "    transforms=get_valid_transforms()\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "\n",
    "    config.num_classes = 1\n",
    "    config.image_size=512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval();\n",
    "    return net.cuda()\n",
    "\n",
    "net = load_net('../input/wheat-effdet5-fold0-best-checkpoint/fold0-best-all-states.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(images, score_threshold=0.22):\n",
    "    images = torch.stack(images).cuda().float()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        det = net(images, torch.tensor([1]*images.shape[0]).float().cuda())\n",
    "        for i in range(images.shape[0]):\n",
    "            boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "            scores = det[i].detach().cpu().numpy()[:,4]\n",
    "            indexes = np.where(scores > score_threshold)[0]\n",
    "            boxes = boxes[indexes]\n",
    "            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "            predictions.append({\n",
    "                'boxes': boxes[indexes],\n",
    "                'scores': scores[indexes],\n",
    "            })\n",
    "    return [predictions]\n",
    "\n",
    "def run_wbf(predictions, image_index, image_size=512, iou_thr=0.44, skip_box_thr=0.43, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for j, (images, image_ids) in enumerate(data_loader):\n",
    "    break\n",
    "\n",
    "predictions = make_predictions(images)\n",
    "\n",
    "i = 0\n",
    "sample = images[i].permute(1,2,0).cpu().numpy()\n",
    "\n",
    "boxes, scores, labels = run_wbf(predictions, image_index=i)\n",
    "boxes = boxes.astype(np.int32).clip(min=0, max=511)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "for box in boxes:\n",
    "    cv2.rectangle(sample, (box[0], box[1]), (box[2], box[3]), (1, 0, 0), 1)\n",
    "    \n",
    "ax.set_axis_off()\n",
    "ax.imshow(sample);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prediction_string(boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(scores, boxes):\n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n",
    "    return \" \".join(pred_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for images, image_ids in data_loader:\n",
    "    predictions = make_predictions(images)\n",
    "    for i, image in enumerate(images):\n",
    "        boxes, scores, labels = run_wbf(predictions, image_index=i)\n",
    "        boxes = (boxes*2).astype(np.int32).clip(min=0, max=1023)\n",
    "        image_id = image_ids[i]\n",
    "        \n",
    "        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "\n",
    "        result = {\n",
    "            'image_id': image_id,\n",
    "            'PredictionString': format_prediction_string(boxes, scores)\n",
    "        }\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n",
    "test_df.to_csv('submission.csv', index=False)\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
